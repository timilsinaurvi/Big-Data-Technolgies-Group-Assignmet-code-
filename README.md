# Big-Data-Technolgies-Group-Assignmet-code-
This project uses PySpark to perform end-to-end telecom analytics, including data cleaning, feature engineering, churn label encoding, and session-based transformations. It builds machine-learning models (Logistic Regression, Decision Tree, Random Forest) to predict customer churn and analyzes network congestion by examining traffic and resource utilization. The project also evaluates service plan profitability by calculating revenue patterns and customer distribution. Designed to run in Google Colab, it demonstrates scalable big-data processing and real-world telecom insight generation in a clean, efficient workflow.
And also taking about the file hive_docker_pySpark123 This code sets up PySpark inside Google Colab to simulate Hive-style SQL processing on a telecom dataset. It begins by installing PySpark, creating a SparkSession, and enabling SQL execution. After loading the telecom CSV file into a Spark DataFrame, the project registers it as a temporary SQL table named telecom_data. From there, the notebook runs multiple Hive-like SQL queries to analyze customer behaviorâ€”such as identifying high-value churners, filtering early-churn customers, checking Internet service usage, and evaluating revenue patterns. The entire notebook demonstrates how PySpark can be used as a lightweight alternative to Hive for running SQL queries on large datasets using a distributed engine.
